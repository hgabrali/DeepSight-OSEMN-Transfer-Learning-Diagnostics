# üëÅÔ∏è DeepSight: OSEMN Transfer Learning & Forensic Diagnostics

## üìå Project Overview
**DeepSight** is a comprehensive computer vision project that implements the **OSEMN** (Obtain, Scrub, Explore, Model, iNterpret) framework to solve the CIFAR-10 classification problem. Unlike standard implementations, this project focuses on **forensic diagnostics**, addressing "hidden" issues such as texture leaks, background biases, and semantic ambiguity to ensure robust model performance.

---

## üõ† Technical Workflow (The OSEMN Approach)

### 1. Obtain: Data Acquisition & Environment
![Data Acquisition Placeholder](https://via.placeholder.com/800x200?text=Obtain:+Data+Acquisition+Process)

* **Source:** CIFAR-10 ingestion via modular API integration.
* **Stratified Sampling:** Implemented a stratified downsampling strategy to create a representative prototype subset (20%) while maintaining original class distribution integrity.
* **Success Metrics:** Defined **F1-Score (Macro)** as the primary metric and established a **Minimum Viable Accuracy (MVA)** baseline of 65%.

### 2. Scrub: Data Engineering & Integrity
![Data Scrubbing Placeholder](https://via.placeholder.com/800x200?text=Scrub:+Preprocessing+and+Cleaning)

* **Dimensional Integrity:** Automated pre-batch verification to ensure consistency in input shapes of $(3, 224, 224)$.
* **Advanced Preprocessing:** Comparative analysis of **Bilinear vs. Bicubic interpolation** to mitigate aliasing artifacts.
* **Normalization:** Implemented **Caffe-style normalization** (BGR mean subtraction) to align with pre-trained ResNet weights.
* **Leakage Prevention:** Metadata sanitization to prevent "Class Leakage" via filenames or sequence overlap.

### 3. Explore: Forensic EDA
![Exploratory Data Analysis Placeholder](https://via.placeholder.com/800x200?text=Explore:+Forensic+EDA+Visuals)

* **Spatial Bias Analysis:** Generated **Annotation Density Maps** to identify "Center Bias" in object placement.
* **Color Channel Analysis:** RGB/HSV histogram analysis to detect potential **Background Biases** (e.g., Bird vs. Airplane sky bias).
* **Hypothesis Generation:** Identified **Semantic Ambiguity** (Car vs. Truck) and distinguished between **Rigid vs. Organic features** for custom augmentation strategies.

### 4. Model: Two-Phase Transfer Learning
![Model Architecture Placeholder](https://via.placeholder.com/800x200?text=Model:+ResNet18+Transfer+Learning+Pipeline)

* **Phase 1: Frozen Base:** Feature extraction using **ResNet18** with a custom-reconstructed **Fully Connected (FC) head**.
* **Phase 2: Fine-Tuning:** Strategic unfreezing of deeper layers (**Stage 3 & 4**) for domain adaptation.
* **Optimization:** Utilized **Differential Learning Rates** and `ReduceLROnPlateau` scheduling for smooth optimization and convergence.
* **Augmentation:** Applied a dual-strategy pipeline (**Geometric & Photometric**) using the **Albumentations** library.

### 5. iNterpret: Diagnostic Evaluation
![Model Interpretation Placeholder](https://via.placeholder.com/800x200?text=iNterpret:+Grad-CAM+and+Confusion+Matrix)

* **Convergence Analysis:** Visualization of Loss/Accuracy curves to monitor for overfitting.
* **Limits of Resolution:** Confusion Matrix analysis to pinpoint semantic swapping (e.g., the **"Car-Truck Boundary"**).
* **Blind Spot Analysis:** Leveraged **Grad-CAM** (Gradient-weighted Class Activation Mapping) to verify if the model learns shapes (Global features) or simply exploits **Texture Leaks** (Local features).

---

## üìä Key Results

| Metric | Value |
| :--- | :--- |
| **Final Accuracy** | ~84% (Validation) |
| **Macro F1-Score** | 0.82 |
| **Bias Detection** | Grad-CAM confirmed focus on object features rather than background noise for 90% of test samples. |

---
*Generated by GitHub English Expert*
